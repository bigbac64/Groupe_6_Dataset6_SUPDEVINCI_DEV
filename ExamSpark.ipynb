{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "informal-egyptian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "def get_spark_env(version, job_name, n):\n",
    "    if version in [\"2.4\"]:\n",
    "        from pyspark.sql import SparkSession\n",
    "        spark = SparkSession.builder.master(\"local[*]\").config('spark.executor.memoryOverhead.config', n).appName(job_name).getOrCreate()\n",
    "        return spark\n",
    "    elif version in [\"1.6\"]:\n",
    "        return None, None\n",
    "\n",
    "def Print_DF(DF):\n",
    "    return DF.select(\"*\").toPandas()\n",
    "\n",
    "def Print_DF_Rows(DF,NbRows):\n",
    "    return pd.DataFrame(DF.take(NbRows),columns=DF.columns)\n",
    "\n",
    "job_name = 'Formation'\n",
    "spark = get_spark_env(\"2.4\", job_name, '3')\n",
    "print (spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "textile-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delColumn(df, drop_list):\n",
    "    \"\"\"\n",
    "    Fonction qui supprimer les colonne comportant le nom donné\n",
    "\n",
    "    df: pandas.dataframe -> data a traité\n",
    "    drop_list: str[] -> valeur qui permettras d'effectuer la suppression des colonne choisi\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.select([column for column in df.columns if column not in drop_list])\n",
    "\n",
    "def cleanerData(df, column=[], letNan=False):\n",
    "    \"\"\"\n",
    "    Fonction qui a pour role d'éffacer les valeurs erroné dans la dataframe\n",
    "    \n",
    "    df: pandas.dataframe -> data a traité\n",
    "    column: str[] -> selectionne la colonne en particulier\n",
    "    letNan: bool -> si il est activé toute les valeurs erronés seront null et non remplacé par la moyenne de la colonne\n",
    "    \"\"\"\n",
    "    \n",
    "    if column == []:\n",
    "        for col in df.columns:\n",
    "            df.withColumn(col, when(type(f.col(col)) == str and f.col(col) < 0,np.nan))\n",
    "    else:\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def decribeData(df, nbNan=False, selectColumns=(), mode=\"\"):\n",
    "    \"\"\"\n",
    "    Fonction pour generer une description de la data selon differente option\n",
    "    \n",
    "    df: pandas.dataframe -> data a traité\n",
    "    nbNan: bool -> pour compter le nombre de valeur null\n",
    "    selectColumns: str() -> pour traiter des colonne specifique\n",
    "    mode: str -> mode possible; mean, min, max, median, type:int[] liste des quantiles recherché\n",
    "    \"\"\"\n",
    "    described = df\n",
    "    if selectColumns != ():\n",
    "        described = df.select(*selectColumns)\n",
    "    \n",
    "    if nbNan:\n",
    "        if selectColumns != ():\n",
    "            print('\\033[93m' + \"SELECTCOLUMNS Warn:\"+ '\\033[95m' +\" si nbNan est actif SELECTCOLUMNS ne sert a rien\")\n",
    "        if mode != \"\":\n",
    "            print('\\033[93m' + \"MODE Warn:\"+ '\\033[95m' +\" si nbNan est actif MODE ne sert a rien\")\n",
    "        if roundValue != -1:\n",
    "            print('\\033[93m' + \"ROUNDVALUE Warn:\"+ '\\033[95m' +\" si nbNan est actif ROUNDVALUE ne sert a rien\")\n",
    "        return df.select([f.count(f.when(f.col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "    \n",
    "    if mode == \"mean\":\n",
    "        described = df.select(*[f.avg(c) for c in df.columns])\n",
    "    elif mode == \"min\":\n",
    "        described =  df.select(*[f.min(c).alias(c) for c in df.columns])\n",
    "    elif mode == \"max\":\n",
    "        described =  df.select(*[f.max(c).alias(c) for c in df.columns])\n",
    "    elif mode == \"median\":\n",
    "        described =  df.approxQuantile([c for c in df.columns],[0.5], 0.25)\n",
    "    elif type(mode) == list:\n",
    "        return df.approxQuantile([c for c in df.columns],mode, 0.25)\n",
    "\n",
    "    if mode != \"\":\n",
    "        return described\n",
    "    \n",
    "    described = described.summary()\n",
    "    \n",
    "    return described"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "extended-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERSION PANDAS\n",
    "def cleanerData(df, columns=[], letNan=False):\n",
    "    \"\"\"\n",
    "    Fonction qui a pour role d'éffacer les valeurs erroné dans la dataframe\n",
    "    \n",
    "    df: pandas.dataframe -> data a traité\n",
    "    column: str[] -> selectionne la colonne en particulier\n",
    "    letNan: bool -> si il est activé toute les valeurs erronés seront null et non remplacé par la moyenne de la colonne\n",
    "    \"\"\"\n",
    "    if columns == []:\n",
    "        for col in df:\n",
    "            df[col] = pd.to_numeric(df[col],errors='coerce')\n",
    "            df[col] = df[col].apply(lambda x: np.nan if x < 0 else x)\n",
    "            if not letNan :\n",
    "                mean = df[col].mean()\n",
    "                df[col] = df[col].apply(lambda x: mean if x == 0 or np.isnan(x) else x)\n",
    "    else:\n",
    "        for col in columns:\n",
    "            df[col] = pd.to_numeric(df[col],errors='coerce')\n",
    "            df[col] = df[col].apply(lambda x: np.nan if x < 0 else x)\n",
    "            if not letNan:\n",
    "                mean = df[col].mean()\n",
    "                df[col] = df[col].apply(lambda x: mean if x == 0 or np.isnan(x) else x)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "listed-lindsay",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "filter expression '`fixed acidity`' of type string is not a boolean.;\nFilter fixed acidity#4314: string\n+- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n   +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n      +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n         +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n            +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n               +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n                  +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n                     +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n                        +- Relation[_c0#4307,Unnamed: 0#4308,Unnamed: 0.1#4309,Unnamed: 0.1.1#4310,Unnamed: 0.1.1.1#4311,Unnamed: 0.1.1.1.1#4312,Unnamed: 0.1.1.1.1.1#4313,fixed acidity#4314,volatile acidity#4315,citric acid#4316,residual sugar#4317,chlorides#4318,free sulfur dioxide#4319,total sulfur dioxide#4320,density#4321,pH#4322,sulphates#4323,alcohol#4324,quality#4325] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-606be3691a26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#tmp = cleanerData(df.toPandas())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df = spark.createDataFrame(tmp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanerData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-142-fdf20b4ed758>\u001b[0m in \u001b[0;36mcleanerData\u001b[0;34m(df, columns, letNan)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mletNan\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"condition should be string or Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: filter expression '`fixed acidity`' of type string is not a boolean.;\nFilter fixed acidity#4314: string\n+- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n   +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n      +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n         +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n            +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n               +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n                  +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n                     +- Project [fixed acidity#4314, volatile acidity#4315, citric acid#4316, residual sugar#4317, chlorides#4318, free sulfur dioxide#4319, total sulfur dioxide#4320, density#4321, pH#4322, sulphates#4323, alcohol#4324, quality#4325]\n                        +- Relation[_c0#4307,Unnamed: 0#4308,Unnamed: 0.1#4309,Unnamed: 0.1.1#4310,Unnamed: 0.1.1.1#4311,Unnamed: 0.1.1.1.1#4312,Unnamed: 0.1.1.1.1.1#4313,fixed acidity#4314,volatile acidity#4315,citric acid#4316,residual sugar#4317,chlorides#4318,free sulfur dioxide#4319,total sulfur dioxide#4320,density#4321,pH#4322,sulphates#4323,alcohol#4324,quality#4325] csv\n"
     ]
    }
   ],
   "source": [
    "df = delColumn(df, ['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', 'Unnamed: 0.1.1.1.1', 'Unnamed: 0.1.1.1.1.1', 'Unnamed: 0.1.1.1.1.1.1', '_c0'])\n",
    "#tmp = cleanerData(df.toPandas())\n",
    "#df = spark.createDataFrame(tmp)\n",
    "df = cleanerData(df)\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "rental-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load('Dataset_6_quality.csv', format=\"csv\", sep=\"|\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "certified-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Can't extract value from Unnamed: 0#4308: need struct type but got int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-82136c4781e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecribeData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselectColumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"residual sugar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"citric acid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"volatile acidity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"median\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-120-3936fedd893c>\u001b[0m in \u001b[0;36mdecribeData\u001b[0;34m(df, nbNan, selectColumns, mode)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdescribed\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"median\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdescribed\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapproxQuantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapproxQuantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mapproxQuantile\u001b[0;34m(self, col, probabilities, relativeError)\u001b[0m\n\u001b[1;32m   2311\u001b[0m         \u001b[0mrelativeError\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelativeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2313\u001b[0;31m         \u001b[0mjaq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapproxQuantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelativeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2314\u001b[0m         \u001b[0mjaq_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjaq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjaq_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misStr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mjaq_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Can't extract value from Unnamed: 0#4308: need struct type but got int"
     ]
    }
   ],
   "source": [
    "decribeData(df, selectColumns=(\"residual sugar\", \"citric acid\", \"volatile acidity\"), mode=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-capture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-assessment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
